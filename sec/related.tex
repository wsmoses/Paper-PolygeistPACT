\section{Related Work}


%Other proprietary compilers, such as IBM~XL~\cite{ibmxl_polyhedral} and R-Stream~\cite{rstream}, use polyhedral techniques and rely on extractor tools, but as these are proprietary little documentation is available. OpenScop~\cite{openscop} is a textual exchange format, produced by Clan among others, allowing to capture and exchange \scop.
%\lc{This OpenScop is a bit left alone.}
%\az{It is kinda the only "exchange format" out there.}


\paragraph{MLIR Frontends}

Since the adoption of MLIR under the LLVM umbrella, several frontends have been created for generating MLIR from domain-specific languages. Teckyl~\cite{teckyl} connects the productivity-oriented Tensor Comprehensions~\cite{tc} notation to MLIR's Linalg dialect. Flang---the LLVM's Fortran frontend---models Fortran-specific constructs using the FIR dialect~\cite{flang}. COMET, a domain-specific compiler for chemistry, introduces an MLIR-targeting domain-specific frontend from a tensor-based language~\cite{comet}. NPComp aims at providing the necessary infrastructure to compile numerical Python and PyTorch programs taking advantage of the MLIR infrastructure~\cite{npcomp}. PET-to-MLIR converts a subset of polyhedral C code to MLIR's Affine dialect by parsing \icode{pet}'s internal representation. In addition to currently not handling specific constructs (\icode{if}s, symbolic bounds, and external function calls), parsing \icode{pet}'s representation limits the frontend's usability as it cannot interface with non-polyhedral code such as initialization, verification, or printing routines~\cite{komisarczyk2020pet}. In contrast, \tool generates MLIR from non-polyhedral code (though not necessarily in the Affine dialect). CIRCT is a new project under the LLVM umbrella that aims to apply MLIR development methodology to the electronic design automation industry~\cite{circt}. Stripe uses MLIR Affine dialect as a substrate for loop transformations in machine learning models, including tiling and vectorization, and accepts a custom DSL as input~\cite{stripe}.

\paragraph{Compilers Leveraging Multiple Representations}

The SUIF compiler infrastructure pioneered a combined internal representation that supports higher-level transformations, including loop optimization and parallelization~\cite{wilson1994suif} and, in particular, reduction parallelization~\cite{hall1996maximizing}. \tool leverages MLIR abstractions unavailable in SUIF: regular and affine \icode{for} loops, OpenMP reduction constructs, etc. It also benefits from the SSA+regions form, which is only available as external extension in SUIF~\cite{holloway2002machine}, for IR simplification. PIPS supports loop transformations and inter-procedural optimization when targeting OpenMP~\cite{amini2011pips,amini2012par4all}. \tool differs from both by emitting machine code rather than source code, which allows it to emit parallel runtime and other directives that have no representation in the source language such as C.

\paragraph{Combining ``Classical'' and Polyhedral Flows}

Few papers have focused on combining ``classical'', mostly AST-level, and polyhedral transformations. PolyAST pioneered the approach by combining an affine scheduler with AST-level heuristics for fusion and tiling~\cite{polyast}, although similar results were demonstrated with only polyhedral transformations~\cite{spatial_scheduler}. An analogous approach was experimented in CUDA-CHiLL~\cite{zhang2016combining}. Arguably, many automated polyhedral flows perform loop fusion and/or tiling as a separate step that can be assimilated to classical transformations. Pluto~\cite{Bondhugula2008Pluto} uses several ``syntactic'' postprocessing passes to exploit spatial locality and parallelism in stencils~\cite{spatial_report}. Several tools have been proposed to drive polyhedral loop transformations with scripts using classical loop transformations such as fusion and permutation as operations, including URUK~\cite{uruk}, CHiLL~\cite{chill} and Clay~\cite{clay}. \tool differs from all of these because it preserves the results of such transformations in its IR \emph{along with} polyhedral constructs and enables interaction between different levels of abstraction.

\paragraph{Additional (Post-)Polyhedral Transformations}

Support for handling reduction loops was proposed in Polly~\cite{polly_reduction}, but the code generation is not implemented. At the syntactic level, reduction support was added to PET via manual annotation with \textsc{Pencil} directives~\cite{reduction_drawing}. R-Stream reportedly uses a variant of statement splitting to affect scheduler's behavior and optimize memory consumption~\cite{rstream}. \textsc{PolySIMD} uses variable renaming around \textsc{PPCG} polyhedral flow to improve vectorization~\cite{chatarasi2018unified}. \tool automates these leveraging both SSA and polyhedral information.

%\wmnote{I feel like this needs restructure to more conclusively say why polyhedral important, and why lacking more directly, will attempt a stab at in a bit....Future me: deciding to wait til after we chat/have a conclusive idea of what the story is overall before trying to do a pass over}
%\az{We could start with MLIR rather than polyhedral, it may be more catchy for the audience.}
%\wmnote{yeah I think that may be wise, though I guess for me generally the more catchy thing would be explaining a problem in existing flows, partial soltns (e.g. polly/pluto), and then a 10s intro to what we are.}
%\rz{Maybe it would be better to emphasize that we are focusing on polyhedral compilation flow (which is roughly the sentence ``The process of \dots'') instead of the polyhedral model in the beginning? My personal understanding of Polygeist is: the challenge in existing flows is the gap between the pipeline - program -> polyhedra -> program, and Polygeist tries to use MLIR to fill them (program -> MLIR -> polyhedra -> MLIR -> program). Putting MLIR to the start might be a bit distracted IMO.}

%The polyhedral model has remained on the cutting edge of research into compiler optimizations for several decades~\cite{feautrier2011polyhedron}.
%It provides deep loop analysis and restructuring capabilities by transforming the input program into a mathematical abstraction based on integer sets and binary relations, reasoning on this abstraction and generating the new, optimized code.
%The process of transforming the program from the representations commonly used in production compilers such as LLVM intermediate representation (IR)~\cite{llvm} or syntax tree is non-trivial~\cite{grosser.ppl.2012,pop2006graphite}, and the inverse process is even more complex~\cite{cloog,razanajato2017splitting,grosser2015polyhedral}.
%This process, together with high algorithmic complexity of the underlying transformation mechanism, has led to the polyhedral optimization being rather poorly adopted by compilers beyond research.

%MLIR is a new compiler infrastructure proposed and developed in the scope of the LLVM project~\cite{mlir}.
%One of its design goals is to provide a production-grade infrastructure that simplifies the expression of advanced compiler optimization, particularly those that require casting the input program into an additional, higher-level abstraction.
%MLIR has always considered the polyhedral representation as a first-class citizen in its infrastructure~\cite{mlir_rationale} and attempts to address the complexity and comprehensibility issues of the polyhedral model by designing and implementing all relevant algorithms from scratch. It uses a simplified representation that updates the code after each transformation instead of relying on a monolithic code generation mechanism~\cite{mlir_simplified_polyhedral}.
%\rz{Just feel that this paragraph is a bit disconnected from the previous one. We just show that the two problems of polyhedral compilation (the transformation process and algorithmic complexity), maybe after it we could directly dive into what we think is the best solution for the process problem (we don't care about poly algo), and then we can lead MLIR in.}

%The design of MLIR's affine representation~\cite{mlir_affine} makes it challenging to directly apply existing polyhedral tools, which are often based on \icode{isl}~\cite{isl} or \icode{Polylib}~\cite{polylib} and designed for C source-to-source transformation~\cite{Bondhugula2008Pluto,ppcg}. MLIR also does not include an automated polyhedral scheduler. Moreover, no benchmarks relevant for polyhedral optimization are available in MLIR. At the same time, MLIR's unique representation that combines structured region-based control flow with SSA form offers unique opportunities for combining ``classical'' SSA-based and polyhedral compiler optimizations.

%We propose \tool as a platform to connect MLIR with existing polyhedral optimizers, contributing several new techniques. First, we create a \icode{Clang}-based C and C++ MLIR frontend capable of identifying static control parts of the program (\scop) to produce the Affine dialect~\cite{mlir_affine}\rz{Should we explain what is dialect?} along with other ``standard'' MLIR dialects. Second, we implement a bi-directional conversion between the MLIR Affine dialect and the OpenScop format~\cite{openscop}. This enables a flow that originates in MLIR, uses existing standalone polyhedral tools, and returns to MLIR for further transformations and code generation. Finally, we propose two additional transformations, statement splitting and reduction parallelization, that leverage by \tool's IR\rz{It is not very clear what is Polygeist's IR, and maybe we should describe what are the objectives of these transformations (especially for statement splitting), e.g., to reduce run time.}. These transformations together with associated heuristics would have been challenging, if not impossible, to implement on either C or LLVM IR~\cite{polly_reduction,reduction_drawing}. We demonstrate that \tool can process the benchmarks of interest without significant overhead and that MLIR transformations compose with existing polyhedral flows. The combination of these contributions makes \tool competitive with state-of-the-art polyhedral compilers operating on LLVM~IR~\cite{grosser.ppl.2012} and on C~\cite{Bondhugula2008Pluto}.
%\rz{Maybe we can mention the name of Polly and Pluto here? People may find it more intriguing.}
%\az{Nah. Those who read until there will at least skim the rest. We mentioned tool names in the abstract. Also, MLIR is catchier than either of the tools anyway.}

% \az{I dropped the parts about benchmark comparisons and ablation studies because this is no longer the point of the paper}
% sg -wm

%\rz{I'm a bit confusedby the term extractor. To me it sounds like these tools simply transform from one source (IR/C) to polyhedral representation, but the description in this section actually mentions much about what kind of optimisation we can provide IMO}
\paragraph{Integration of Polyhedral Optimizers into Compilers}

Polyhedral optimization passes are available in production (GCC~\cite{pop2006graphite}, LLVM~\cite{grosser.ppl.2012}, IBM~XL~\cite{ibmxl_polyhedral}) and research (R-Stream~\cite{rstream}, ROSE~\cite{quinlan2000rose}) compilers. In most cases, the polyhedral abstraction must be extracted from a lower-level representation before being transformed and lowered in a dedicated code generation step~\cite{cloog,grosser2015polyhedral}. This extraction process is not guaranteed and may fail to recover high-level information available at the source level~\cite{delinearization}. Furthermore, common compiler optimizations such as LICM are known to interfere with it~\cite{delicm}. \tool maintains a sufficient amount of high-level information, in particular loop and n-D array structure, to circumvent these problems by design.

Source-to-source polyhedral compilers such as Pluto~\cite{Bondhugula2008Pluto} and \textsc{ppcg}~\cite{ppcg} operate on a C or C++ level. They lack interaction with other compiler optimizations and a global vision of the code, which prevents, e.g., constant propagation and inlining that could improve the results of polyhedral optimization. Being positioned between the AST and LLVM IR levels, \tool enables the interaction between higher- and lower-level abstractions that is otherwise reduced to compiler pragmas, i.e. mere optimization hints. Furthermore, \tool can rely on MLIR's progressive raising~\cite{mlir_raising} to target abstractions higher level than C code with less effort than polyhedral frameworks~\cite{tactics}.

%Source-level polyhedral extractor tools such as Clan~\cite{bastoul2008clan} and \icode{pet}~\cite{pet} identify parts of a C source code suitable for polyhedral optimization (commonly referred to as static-control parts, or \scop) and provide suitable APIs.
